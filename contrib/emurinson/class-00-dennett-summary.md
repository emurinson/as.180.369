In a piece for The Atlantic titled The Problem of Counterfeit People, philosopher Daniel Dennett takes his stab at proposing a potential solution to the threats AI misuse poses to human freedom. In line with his title for the piece, Dennett compares the new counterfeiting scheme of deepfake AI to the age-old phenomenon of counterfeiting money. However, he makes certain to underscore the key differences between counterfeit currency and this new technology that render it "the most dangerous artifact in human history." 

First, Dennett observes that our natural desire to feel understood and converse with something that "talk[s] sensibly," has propelled an explosion of industries centered on developing technologies capable of deceiving us into thinking they're human. Driven by what he calls our inclination towards the "intentional stance," technology corporations get tremendous financial incentives for making it more and more difficult to distinguish between a computer-generated humanoid and real humans. In the most fundamental sense, this destroys any ability we have to trust one another in any non face-to-face interaction. Strategically, he invokes the still fresh in our minds COVID-19 crisis, calling the rapid spread of misused AI "another pandemic...this time attacking the fragile control systems in our brains." If anything, he says, AI should scare us more than physical ailments as it has the potential to turn us into "passive and ignorant pawns" in its computer-driven chess game. 

Second, he laments that this technology risks destroying all democracy as we know it. Although the counterfeiting of currency has the potential to be financially devastating to any number of people, counterfeit people have the ability to deceive and control our minds. Dennett describes a dystopian future in which AI technology is used to entrap and blackmail citizens into subjugation and further manipulation by any government or corporation that wishes to do so.  Over time, as freedom and trust are further eroded, civilization as we know it will be lost. 

Finally, the AI technology differs from traditional counterfeiting in that it possesses the creative ability to create new iterations of itself. This technology is self-teaching and self-improving, such that over time it becomes more resilient to human control and better able to pass as human. Scared to countenance the prospect of AI’s creators losing control of it, Dennett merely invokes the image of the constantly reproducing evil brooms from Disney’s fantasy world and gloomily hopes that “there is a non-magical way” to stem the threat posed by the loss of control of AI.

Even as he lays out the added complexities and threats AI poses in comparison to traditional counterfeiting of money, Dennett maintains that one of the few potential solutions to the AI problem derives from the mechanism with which modern economies combat counterfeiting. The EURion Constellation found on most modern paper currency is recognized by software installed on almost all manufactured printers and scanners. Developed governments created legislation to ensure that the manufacturers of the tools necessary to counterfeit money, install software that makes it impossible for their products to be co-opted by bad actors. So too, the most compelling way to prevent the abuse of AI is to force AI makers to incorporate a ‘Constellation’ in all related computer code, such that bad actors won’t have the ability to pass of an AI re-creation as genuinely human. 

Dennett first mentions incentives for corporations and governments to implement this measure, but immediately proceeds to speak almost exclusively of ‘sticks’ instead of ‘carrots.’ He repeatedly mentions the prospect of severe and excruciating punishments for those who violate the public’s trust through the misuse of AI. He posits that the extraordinary potential for monetary profit that AI offers should be reason enough for corporations to want to comply with any proposed regulations on the new technology. At the same time, he acknowledges that it’s possible that it is already too late to prevent the unbridled proliferation of this technology to bad actors. 

To wrap up the piece, Dennett reverts from the pragmatic argument to the moral argument and appeals to the conscience of AI developers. He reminds us that if we are to allow this dangerous technology to spread unchecked, we’ll all be complicit in undermining personal identity, freedom, trust, and life as we know it. 

Some thoughts of my own: 

At one point, Dennett laments that we may one day become passive and ignorant pawns if AI is used to manipulate us. But in my eyes, in many ways, we have already become passive and ignorant pawns. To me, it seems like there’s a fundamental laziness that pervades our modern life, and modern technology is constantly being used to enhance this laziness. In the Harari article that Dennett mentions, YNH asks why scroll through news when you can just ask AI? But I think that until they develop an AI that asks for you, people will keep scrolling and reading because it takes more creative energy and it’s harder to be lazy when you have to think of what you want instead of it being fed to you…in general, there’s a trend to more convenience, less decision making, less creative thinking, etc. 

I think that the biggest irony here by far is that we’re using AI to critique AI…Now, I realize that Prof. Carroll wants us to use ChatGPT the right way and not to rely on it to do the work for us, but isn’t it so that the real feat is to make sure that the correct use of potentially dangerous things is actually sustained through generations? Don’t you know that’s not what really happens. Almost always, people who haven’t yet developed full maturity don’t want to use the new technology in the proper way and then the issues and dangers start to resurface. Even as our intentions and methods are proper now, won’t integrating AI eventually devolve into what we don’t want it to become?
